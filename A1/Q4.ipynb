{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lkIzqqprVroX"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wp73uR5XWEAa"
      },
      "outputs": [],
      "source": [
        "## Actions, rewards and Transition probabilities\n",
        "## Do now change the values here\n",
        "\n",
        "A = {0: [(1, 0.5, 1), (2, 0.5, 2)], 1: [(2, 0.2, 4), (3, 0.8, 1)]}\n",
        "B = {0: [(1,1,0)]}\n",
        "C = {0: [(1,1,1)], 1: [(3,1,3)]}\n",
        "D = {0: [(3,1,0)]}\n",
        "\n",
        "STATE_SPACE = {0 : A, 1 : B, 2 : C, 3 : D}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ts3A8DMKf8z5"
      },
      "outputs": [],
      "source": [
        "state_space = list(STATE_SPACE.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noMPUgtzgDHx",
        "outputId": "b489d589-6b03-4625-d524-c63560219d63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "state_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gELZvvECYT8D"
      },
      "outputs": [],
      "source": [
        "# Get access to actions corresponding to a state from STATE_SPACE\n",
        "# You can loop over elements of  get_actions(state) to get your elements\n",
        "def get_actions(state):\n",
        "  return list(STATE_SPACE[state].keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06uM8kjygMGC",
        "outputId": "34ecaca2-12b3-4bac-ba47-a300bc33ac5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "state: 0 , actions: [0, 1]\n",
            "state: 1 , actions: [0]\n",
            "state: 2 , actions: [0, 1]\n",
            "state: 3 , actions: [0]\n"
          ]
        }
      ],
      "source": [
        "for state in state_space:\n",
        "  print(\"state:\", state, \", actions:\",  get_actions(state))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LNoV3N7cYQfY"
      },
      "outputs": [],
      "source": [
        "# input : state1, state2, action = a\n",
        "# output = (p, r) where p is the transition probability of reaching state2 from\n",
        "#           state1 when action a is taken and r = reward obtained in the process.\n",
        "\n",
        "def get_transition_prob_and_reward(x,y, action):\n",
        "  probs = STATE_SPACE[x][action]\n",
        "  for prob in probs:\n",
        "    if prob[0] == y:\n",
        "      return (prob[1], prob[2])\n",
        "  return (0,0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2FVXUUm4cWKM"
      },
      "outputs": [],
      "source": [
        "# input is state = t, action = a.\n",
        "# output is a list of tuples of the form (s, p, r) where\n",
        "#     s = next state\n",
        "#     p = transition probability of next state being s when current state is t and action taken is a\n",
        "#     r = reward obtained in the process\n",
        "\n",
        "def transition_probs_and_rewards(state, action):\n",
        "  return STATE_SPACE[state][action]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc7VDAcjZzIZ",
        "outputId": "1623529a-9370-4b21-ae88-0e0b2c5711ec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 0)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#  Example usage\n",
        "get_transition_prob_and_reward(1,1,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G-Sfn0gckTw",
        "outputId": "c1e8dc34-1970-4a23-a6bf-299ddec8170f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 1, 0)]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example usage\n",
        "transition_probs_and_rewards(1,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "2B61NW3VbeKp"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "#Modify and use these values in value_iteration function\n",
        "gamma = 0.99  # Discount factor\n",
        "theta = 1e-6  # Convergence threshold\n",
        "max_iterations = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "MNBM2YpsbtbH"
      },
      "outputs": [],
      "source": [
        "#Value function: modify this in the value_iteration function\n",
        "V = np.zeros(4)\n",
        "\n",
        "#policy Iteration: modify this in find best policy function\n",
        "Policies = np.zeros(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "L0O16eLXZ5_I"
      },
      "outputs": [],
      "source": [
        "def value_iteration():\n",
        "  global V\n",
        "  # write your code here to modify V\n",
        "  for _ in range(max_iterations):\n",
        "    delta = 0\n",
        "    new_V = np.zeros(4)\n",
        "    for state in state_space:\n",
        "      max_val = -1\n",
        "      for action in get_actions(state):\n",
        "        val = 0\n",
        "        for next_state, prob, reward in transition_probs_and_rewards(state, action):\n",
        "          val += prob * (reward + gamma * V[next_state])\n",
        "        max_val = max(max_val, val)\n",
        "      new_V[state] = max_val\n",
        "      delta = max(delta, abs(V[state] - new_V[state]))\n",
        "    V = new_V\n",
        "    if delta < theta:\n",
        "      break\n",
        "\n",
        "  return V\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JGVuMy-GcLh0"
      },
      "outputs": [],
      "source": [
        "def find_best_policy():\n",
        "  global Policies\n",
        "  # write your code here to modify Policies\n",
        "  for state in state_space:\n",
        "    max_val = -1\n",
        "    for action in get_actions(state):\n",
        "      val = 0\n",
        "      for next_state, prob, reward in transition_probs_and_rewards(state, action):\n",
        "        val += prob * (reward + gamma * V[next_state])\n",
        "      if val > max_val:\n",
        "        max_val = val\n",
        "        Policies[state] = action\n",
        "\n",
        "  return Policies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0., 0., 0., 0.]), array([0., 0., 0., 0.]))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "V, Policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2.985, 0.   , 3.   , 0.   ]), array([0., 0., 1., 0.]))"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "value_iteration()\n",
        "find_best_policy()\n",
        "V, Policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
